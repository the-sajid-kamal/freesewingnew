import matter from 'gray-matter'
import path from 'node:path'
import yaml from 'js-yaml'
import { readDirectory, readFile, writeFile } from '../../../scripts/fs.mjs'
import { i18n } from '@freesewing/collection'

/*
 * Shared header to include in written .js files
 */
export const header = `/*
 *  This file was auto-generated by the prebuild script
 *  Any changes you make to it will be lost on the next (pre)build.
 */
`

/*
 * Ensure key can be used in an import statement
 */
const toImportKey = (key) =>
  key.split('-').join('').split(' ').join('').split('(').join('').split(')').join('')

/*
 * Helper method to generate the jargon imports umbrella file
 */
const ensureJargonImports = async () => {
  const data = []
  const imports = []
  const glob = {
    sewing: './docs/docs/sewing',
  }
  const pages = {}
  for (const section in glob) {
    pages[section] = (await readDirectory(path.resolve(glob[section])))
      .filter((dir) => dir !== 'readme.mdx')
      .map((page) => page.split(`${path.resolve(glob[section])}/`).pop())

    for (const page of pages[section]) {
      const file = path.resolve(`${glob[section]}/${page}/readme.mdx`)
      const md = await readFile(file)
      const fm = matter(md)
      const key = fm.data.title
      const ikey = toImportKey(key)
      imports.push(
        `import ${ikey}, { frontMatter as ${ikey}Fm } from '@site${glob[section].slice(1)}/${page}/readme.mdx'`
      )
      data.push(
        `  "${fm.data?.term ? fm.data.term.toLowerCase() : key.toLowerCase()}": {` +
          `title: "${fm.data?.title ? fm.data.title : key.toUpperCase()}", ` +
          `aliases: ${fm.data?.aliases ? JSON.stringify(fm.data.aliases) : '[]'}, ` +
          `content: ${ikey} }`
      )
    }
  }

  await writeFile(
    path.resolve('./prebuild/jargon.js'),
    header + imports.join('\n') + '\n\n' + 'export default {' + '\n' + data.join(',\n') + '\n}\n'
  )
}

/*
 * Helper method to generate the terminology imports umbrella file
 */
const ensureTerminologyImports = async () => {
  const data = []
  const glob = {
    designs: './docs/docs/designs',
  }
  const pages = {}
  for (const section in glob) {
    pages[section] = (await readDirectory(path.resolve(glob[section])))
      .filter((dir) => dir !== 'readme.mdx')
      .map((page) => page.split(`${path.resolve(glob[section])}/`).pop())

    for (const page of pages[section]) {
      const file = path.resolve(`${glob[section]}/${page}/readme.mdx`)
      const md = await readFile(file)
      if (md === false) {
        // empty folder, ignore
        continue
      }
      const fm = matter(md)
      const key = page
      data.push(
        `  "${key.split('-').join(' ').toLowerCase()}": { ` +
          `title: "${i18n[key].en.t}", ` +
          `aliases: ${fm.data.aliases ? JSON.stringify(fm.data.aliases) : '[]'}, ` +
          `url: "/designs/${key}/" }`
      )
    }
  }

  await writeFile(
    path.resolve('./prebuild/terminology.js'),
    header + 'export default {' + '\n' + data.join(',\n') + '\n}\n'
  )
}

ensureJargonImports()
ensureTerminologyImports()
